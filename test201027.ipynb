{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 머신러닝, 딥러닝 이론\n",
    "\n",
    "1. 베이즈 이론 및 베이즈 분류기에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이즈 이론 : 두 확률 변수의 사전 확률과 사후 확률 사이의 관계를 나타내는 정리로 새로운 정보를 토대로 어떤 사건이 발생했다는 주장에 대한 신뢰도를 갱신해 나가는 방법\n",
    "\n",
    "베이즈 분류기 : 미래의 사건을 추정하기 위해 과거의 사건 데이터를 사용\n",
    "\n",
    "                결과에 대한 전체 확률을 알기 위해 동시에 여러가지 속성에 대한 정보를 고려하는 문제에 베이지안 분류기 사용이 적합하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 이메일에 ‘나이트’라는 단어가 검출되었을 때의 스팸 확률을 수식으로 작성하시오. (베이즈 이론 수식에서 사후확률을 기술하시오)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(스팸|나이트)=p(스팸)*p(나이트|스팸)/p(나이트)\n",
    "\n",
    "사후확률=사전확률(prior)*우도(likelihood)/주변 우도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 나이브 베이지안 분류기가 응용되는 예를 드시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스팸 메일 필터링(텍스트 분류), 네트워크 침입/비정상 행위 탐지(IDS), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 머신러닝 (DNN, CNN, RNN, GAN)\n",
    "\n",
    "1.  recall, f-measure, precision, accuracy에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall(재현율) : 실제 true 중 예측 true의 비율 - TP/(TP+FN)\n",
    "    \n",
    "f-measure : 정밀도와 재현율의 조화평균 \n",
    "\n",
    "precision(정밀도) : 어떤 분류에 해당한다고 예측한 데이터 중 정답 데이터와 얼마나 맞는지 확인 - TP/(TP+FP)\n",
    "\n",
    "accuracy(정답률) : 전체 데이터 중 올바르게 예측한 비율 - (TP+TN) / (TP+FN+FP+TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. cross-validation에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차검증(cross-validation) : 모델을 평가하는 방법 중 하나로 훈련 데이터를 기반으로 모델링을 하고 테스트 데이터로 해당 모델의 성능을 측정한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 과적합이 발생되는 이유와 해결 방법을 기술하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합(overfitting) : 머신러닝에서 학습 data를 과도하게 학습하는 것으로 학습 data가 실제 data의 부분 집합이므로 학습 data에 딱 맞춰 모델을 만들면 실제 data에서 오차가 증가하게 된다.\n",
    "    \n",
    "과적합 해결 방법 : 데이터의 양을 늘린다, 모델의 복잡도를 줄인다, Regularization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 머신러닝 (DNN, CNN, RNN, GAN)\n",
    "\n",
    "선형 회귀 분석 수행시, 다음 함수 및 기법에 대해 설명하시오.\n",
    "1)가설 함수\n",
    "2)분석 알고리즘\n",
    "3)cost 함수\n",
    "4)경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 가설 함수(Hypothesis) : 알고있는 데이터로부터 x와 y의 관계를 유추하여 만든 식\n",
    "    H(x)=Wx+b\n",
    "    \n",
    "2) 분석 알고리즘 : 독립변수와 종속변수가 직선 형태의 관계로 모델이 데이터에 얼마나 잘 맞는지 확인하고 독립변수의 변화가 종속변수에 어떻게 변화되는지 확인한다\n",
    "    \n",
    "3) cost 함수 : 실제값과 예측값에 대한 오차에 대한 식 \n",
    "    cost(W)=y-y.hat\n",
    "\n",
    "4) 경사하강법(Gradient Descent) : cost 함수를 최소화하는 매개 변수인 W와 b를 찾기 위한 작업으로 미분을 활용하여 업데이트 하는 방식으로 최저점을 찾는다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
