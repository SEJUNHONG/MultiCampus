{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.gutenberg.org/\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/6130/6130-0.txt\", filename=\"lliad.txt\")\n",
    "f = open('lliad.txt', 'rb')\n",
    "lines=[]\n",
    "for line in f:\n",
    "    line=line.lower() \n",
    "    line=line.decode('ascii', 'ignore') \n",
    "    if len(line) > 0:\n",
    "        lines.append(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of the iliad, by homer\\r\\n',\n",
       " '\\r\\n',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and most\\r\\n',\n",
       " 'other parts of the world at no cost and with almost no restrictions\\r\\n',\n",
       " 'whatsoever.  you may copy it, give it away or re-use it under the terms of\\r\\n',\n",
       " 'the project gutenberg license included with this ebook or online at\\r\\n',\n",
       " \"www.gutenberg.org.  if you are not located in the united states, you'll have\\r\\n\",\n",
       " 'to check the laws of the country where you are located before using this ebook.\\r\\n',\n",
       " '\\r\\n',\n",
       " 'title: the iliad\\r\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160564\n"
     ]
    }
   ],
   "source": [
    "text=\" \".join(lines)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 3)                 60        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02586487]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[[1.], [2.], [3.], [4.], [5.]]]) # x.shape=(1,5,1) \n",
    "y = np.array([[6.]])\n",
    "\n",
    "xInput = Input(batch_shape=(None, 5, 1))\n",
    "xLstm = LSTM(3)(xInput)\n",
    "xOutput = Dense(1)(xLstm)\n",
    "\n",
    "model = Model(xInput, xOutput)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x, y, epochs=50, batch_size=1, verbose=0)\n",
    "model.predict(x, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, yTrain), (xTest, yTest)=reuters.load_data(num_words=1000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
       "       list([1, 2, 699, 2, 2, 56, 2, 2, 9, 56, 2, 2, 81, 5, 2, 57, 366, 737, 132, 20, 2, 7, 2, 49, 2, 2, 2, 2, 699, 2, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2, 2, 2, 775, 7, 48, 34, 191, 44, 35, 2, 505, 17, 12]),\n",
       "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 2, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 2, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 2, 55, 2, 92, 617, 80, 2, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 2, 7, 2, 81, 5, 187, 11, 15, 9, 2, 201, 5, 47, 2, 18, 478, 2, 5, 2, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),\n",
       "       ...,\n",
       "       list([1, 141, 2, 387, 81, 8, 16, 2, 10, 340, 2, 850, 31, 56, 2, 691, 9, 2, 71, 9, 2, 2, 2, 699, 2, 2, 2, 699, 244, 2, 4, 49, 8, 4, 656, 850, 33, 2, 9, 2, 340, 2, 2, 9, 2, 22, 2, 2, 687, 83, 35, 15, 257, 6, 57, 2, 7, 4, 2, 654, 5, 2, 2, 2, 4, 49, 8, 16, 369, 646, 6, 2, 7, 124, 407, 17, 12]),\n",
       "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 2, 18, 14, 74, 134, 2, 18, 88, 2, 72, 11, 14, 2, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 2, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 2, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 2, 137, 336, 2, 6, 2, 142, 971, 2, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
       "       list([1, 227, 2, 91, 2, 125, 2, 21, 4, 2, 76, 7, 4, 757, 481, 2, 790, 2, 2, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 2, 91, 2, 2, 340, 7, 194, 2, 6, 2, 21, 127, 2, 2, 2, 6, 2, 4, 329, 433, 7, 65, 87, 2, 10, 2, 2, 290, 9, 21, 567, 16, 2, 24, 4, 76, 209, 30, 2, 2, 2, 8, 4, 60, 8, 4, 966, 308, 40, 2, 129, 2, 295, 277, 2, 9, 24, 286, 2, 234, 222, 9, 4, 906, 2, 2, 114, 2, 2, 7, 4, 113, 17, 12])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=np.max(yTrain)+1 # 46ê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=sequence.pad_sequences(xTrain, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest=sequence.pad_sequences(xTest, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain=to_categorical(yTrain) # 0 1 2 3 4 5 ...45   0+1=>1(?????????????????????)\n",
    "yTest=to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense\n",
    "model.add(Embedding(1000,100))\n",
    "model.add(LSTM(100, activation='tanh'))\n",
    "model.add(Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "90/90 [==============================] - 14s 150ms/step - loss: 2.5891 - accuracy: 0.3554 - val_loss: 2.1658 - val_accuracy: 0.4947\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 13s 149ms/step - loss: 2.0401 - accuracy: 0.4949 - val_loss: 1.9754 - val_accuracy: 0.5174\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 14s 152ms/step - loss: 1.9050 - accuracy: 0.5196 - val_loss: 1.7752 - val_accuracy: 0.5508\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 14s 158ms/step - loss: 1.7700 - accuracy: 0.5481 - val_loss: 1.7292 - val_accuracy: 0.5588\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 13s 146ms/step - loss: 1.6663 - accuracy: 0.5668 - val_loss: 1.6851 - val_accuracy: 0.5788\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 13s 146ms/step - loss: 1.5936 - accuracy: 0.5908 - val_loss: 1.6207 - val_accuracy: 0.6011\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 1.4651 - accuracy: 0.6304 - val_loss: 1.5582 - val_accuracy: 0.6073\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 14s 150ms/step - loss: 1.4677 - accuracy: 0.6226 - val_loss: 1.5155 - val_accuracy: 0.6042\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 13s 150ms/step - loss: 1.3680 - accuracy: 0.6540 - val_loss: 1.4476 - val_accuracy: 0.6447\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 1.2896 - accuracy: 0.6726 - val_loss: 1.4380 - val_accuracy: 0.6389\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 1.2085 - accuracy: 0.6862 - val_loss: 1.3991 - val_accuracy: 0.6514\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 14s 153ms/step - loss: 1.1404 - accuracy: 0.7085 - val_loss: 1.3266 - val_accuracy: 0.6781\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 14s 154ms/step - loss: 1.1039 - accuracy: 0.7181 - val_loss: 1.3019 - val_accuracy: 0.6719\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 14s 150ms/step - loss: 1.0612 - accuracy: 0.7336 - val_loss: 1.2692 - val_accuracy: 0.6852\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 14s 155ms/step - loss: 1.0078 - accuracy: 0.7469 - val_loss: 1.2469 - val_accuracy: 0.6883\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 0.9645 - accuracy: 0.7563 - val_loss: 1.2522 - val_accuracy: 0.6928\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 14s 150ms/step - loss: 0.9188 - accuracy: 0.7686 - val_loss: 1.2425 - val_accuracy: 0.7026\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 0.8824 - accuracy: 0.7800 - val_loss: 1.2176 - val_accuracy: 0.7075\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 14s 152ms/step - loss: 0.8522 - accuracy: 0.7853 - val_loss: 1.2138 - val_accuracy: 0.7102\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 13s 150ms/step - loss: 0.8297 - accuracy: 0.7914 - val_loss: 1.2372 - val_accuracy: 0.6959\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 14s 159ms/step - loss: 0.7948 - accuracy: 0.7993 - val_loss: 1.1949 - val_accuracy: 0.7097\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 13s 149ms/step - loss: 0.7568 - accuracy: 0.8104 - val_loss: 1.2476 - val_accuracy: 0.6950\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 13s 147ms/step - loss: 0.7307 - accuracy: 0.8155 - val_loss: 1.2389 - val_accuracy: 0.7066\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 0.6928 - accuracy: 0.8233 - val_loss: 1.2044 - val_accuracy: 0.7182\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 14s 153ms/step - loss: 0.6730 - accuracy: 0.8317 - val_loss: 1.2540 - val_accuracy: 0.7075\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 13s 150ms/step - loss: 0.6574 - accuracy: 0.8323 - val_loss: 1.2634 - val_accuracy: 0.7079\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 14s 155ms/step - loss: 0.6237 - accuracy: 0.8445 - val_loss: 1.2560 - val_accuracy: 0.7128\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 14s 159ms/step - loss: 0.6038 - accuracy: 0.8507 - val_loss: 1.2545 - val_accuracy: 0.7093\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 14s 152ms/step - loss: 0.5823 - accuracy: 0.8543 - val_loss: 1.2443 - val_accuracy: 0.7106\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 0.5522 - accuracy: 0.8638 - val_loss: 1.2781 - val_accuracy: 0.7137\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(xTrain, yTrain, batch_size=100, epochs=30, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 20ms/step - loss: 1.2781 - accuracy: 0.7137\n",
      "[1.2781016826629639, 0.7137132883071899]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-3b5b7ed9917f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  1, 13, ...,  3,  3,  1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"reuters_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmodel=load_model(\"reuters_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
